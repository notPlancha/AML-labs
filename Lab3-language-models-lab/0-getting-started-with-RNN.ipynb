{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNRvVnoPyugt"
      },
      "source": [
        "## Language Models Lab ##\n",
        "\n",
        "Through these notebooks, we will explore different important and interesting techniques, approaches, and uses of language models to address mainly Natural Language Processing tasks.\n",
        "\n",
        "We will explore the following:\n",
        "\n",
        "- Creating Recurrent Neural Networks (RNN) and Long short-term memory (LSTM) networks\n",
        "- Word2Vec\n",
        "    - Continuous Bag-Of-Words (CBOW)\n",
        "- Using RNNS in practice!\n",
        "    - Text classification\n",
        "- Seq2Seq\n",
        "    - Using Torchtext\n",
        "    - Machine Translation\n",
        "- Using Pre-trained models!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaRniyCuyugw"
      },
      "source": [
        "-------------\n",
        "## Basic testing of RNN, LSTM, and GRU ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8f22Tedyugw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLqo9qSRyugx",
        "outputId": "0fb63ab1-0339-4fd2-be11-af8b732bb894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8, 'does': 9, 'machine': 10, 'learning': 11, 'nowadays': 12}\n"
          ]
        }
      ],
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "# What will happen here?\n",
        "training_data = [\n",
        "    # Tags are: DET - determiner; NN - noun; V - verb\n",
        "    # For example, the word \"The\" is a determiner\n",
        "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"Everybody does machine learning nowadays\".split(), [\"NN\", \"V\", \"NN\", \"NN\", \"ADV\", ])\n",
        "]\n",
        "word_to_ix = {}\n",
        "# For each words-list (sentence) and tags-list in each tuple of training_data\n",
        "for sent, tags in training_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix:  # word has not been assigned an index yet\n",
        "            word_to_ix[word] = len(word_to_ix)  # Assign each word with a unique index\n",
        "            \n",
        "print(word_to_ix)\n",
        "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2, \"ADV\": 3}  # Assign each tag with a unique index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4n1mB70yugx"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 12\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "NUM_CLASSES = len(tag_to_ix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e36GGU4yugy"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, epochs):\n",
        "    epoch_loss = []\n",
        "    for epoch in range(epochs):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "        final_loss = 0\n",
        "        for sentence, tags in training_data:\n",
        "            \n",
        "            model.zero_grad()\n",
        "\n",
        "            # get inputs and targets ready for the network!\n",
        "            sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "            targets = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "            # get the tag scores\n",
        "            tag_scores = model(sentence_in)\n",
        "            \n",
        "            loss = criterion(tag_scores, targets)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            final_loss += loss.item()\n",
        "        epoch_loss.append(final_loss)\n",
        "    \n",
        "    return epoch_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_lm3d_6yugy"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_sequence):\n",
        "    with torch.no_grad():\n",
        "        inputs = prepare_sequence(training_data[test_sequence][0], word_to_ix)\n",
        "        tag_scores = model(inputs)\n",
        "        \n",
        "        outputs = []\n",
        "        \n",
        "        print(tag_to_ix)\n",
        "        print(training_data[test_sequence][0])\n",
        "        print(training_data[test_sequence][1])\n",
        "        \n",
        "        for tag_score in tag_scores:\n",
        "            outputs.append(tag_score.topk(1).indices.item())\n",
        "            \n",
        "        print(outputs)\n",
        "        print(\"--------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx9kUT6Kyugz"
      },
      "source": [
        "### Recurrent Neural Networks (RNN) ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq9PTawyyugz"
      },
      "outputs": [],
      "source": [
        "class RNNTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(RNNTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The RNN takes word embeddings as inputs, and outputs hidden states and output\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        \n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        rnn_out, _ = self.rnn(embeds.view(len(sentence), 1, -1)) #The module is expecting [sentence_length, batch_size, embedding_dim]\n",
        "        \n",
        "        # in this case, rnn_out.view(len(sentence), -1) is the same as doing what function?\n",
        "        tag_space = self.hidden2tag(rnn_out.view(len(sentence), -1))\n",
        "        \n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKSA-aUgyugz",
        "outputId": "2cd504c0-22c5-4dfa-800c-43ff6fb25631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4.01319944858551, 3.7409374713897705, 3.5142505168914795, 3.3068745136260986, 3.106687307357788, 2.9086394906044006, 2.712101995944977, 2.5186516642570496, 2.330113708972931, 2.147655189037323, 1.9718610644340515, 1.80312380194664, 1.6419906616210938, 1.4894486665725708, 1.3470511138439178, 1.2166416645050049, 1.0996626317501068, 0.9965263158082962, 0.9065359681844711, 0.8282851129770279, 0.760127991437912, 0.7004872411489487, 0.6479876488447189, 0.6014860197901726, 0.5600533112883568, 0.5229396373033524, 0.4895393028855324, 0.459358274936676, 0.4319900572299957, 0.4070950672030449, 0.38438767939805984, 0.36362361162900925, 0.34459254890680313, 0.3271123170852661, 0.3110240176320076, 0.2961874231696129, 0.2824797108769417, 0.2697916142642498, 0.25802647694945335, 0.2470984198153019, 0.2369306944310665, 0.22745467349886894, 0.21860947087407112, 0.2103400118649006, 0.20259720087051392, 0.19533676654100418, 0.18851905316114426, 0.1821078471839428, 0.17607104033231735, 0.17037911340594292, 0.16500570252537727, 0.159926887601614, 0.1551203839480877, 0.15056659281253815, 0.1462474837899208, 0.1421465240418911, 0.1382484994828701, 0.13453967683017254, 0.13100743107497692, 0.12764005735516548, 0.12442717142403126, 0.12135870009660721, 0.11842583678662777, 0.11562011949717999, 0.11293376982212067, 0.11036001704633236, 0.10789203271269798, 0.10552380420267582, 0.10324969701468945, 0.1010643970221281, 0.09896307997405529, 0.09694119356572628, 0.09499459341168404, 0.09311927482485771, 0.0913114845752716, 0.08956784941256046, 0.08788506872951984, 0.08626030944287777, 0.08469065092504025, 0.08317339234054089, 0.08170607686042786, 0.08028643019497395, 0.07891218364238739, 0.07758127339184284, 0.07629180327057838, 0.07504196092486382, 0.07382973469793797, 0.07265406474471092, 0.07151286769658327, 0.07040486764162779, 0.0693285958841443, 0.06828302890062332, 0.06726664118468761, 0.06627839244902134, 0.06531704217195511, 0.06438169721513987, 0.06347139179706573, 0.0625848900526762, 0.06172149907797575, 0.06088036112487316]\n",
            "{'DET': 0, 'NN': 1, 'V': 2, 'ADV': 3}\n",
            "['The', 'dog', 'ate', 'the', 'apple']\n",
            "['DET', 'NN', 'V', 'DET', 'NN']\n",
            "[0, 1, 2, 0, 1]\n",
            "--------------\n",
            "{'DET': 0, 'NN': 1, 'V': 2, 'ADV': 3}\n",
            "['Everybody', 'read', 'that', 'book']\n",
            "['NN', 'V', 'DET', 'NN']\n",
            "[1, 2, 0, 1]\n",
            "--------------\n",
            "{'DET': 0, 'NN': 1, 'V': 2, 'ADV': 3}\n",
            "['Everybody', 'does', 'machine', 'learning', 'nowadays']\n",
            "['NN', 'V', 'NN', 'NN', 'ADV']\n",
            "[1, 2, 1, 1, 3]\n",
            "--------------\n"
          ]
        }
      ],
      "source": [
        "model = RNNTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "losses = train(model, optimizer, loss_function, 100)\n",
        "print(losses)\n",
        "evaluate(model, 0)\n",
        "evaluate(model, 1)\n",
        "evaluate(model, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwYT4FQIyugz"
      },
      "source": [
        "### Long Short-Term Memory (LSTM) ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhmV_MvXyug0"
      },
      "outputs": [],
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OvO6qY8yug0",
        "outputId": "f884ed14-8f9c-4613-990b-da8cf7c6525d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4.257006525993347, 4.126981019973755, 4.017700791358948, 3.925899624824524, 3.848695755004883, 3.7835817337036133, 3.728405475616455, 3.6813430786132812, 3.640865445137024, 3.6057045459747314, 3.574816584587097, 3.5473484992980957, 3.522607207298279, 3.5000311136245728, 3.4791669845581055, 3.4596489667892456, 3.4411827325820923, 3.4235302209854126, 3.4064990282058716, 3.389933228492737, 3.3737049102783203, 3.3577096462249756, 3.3418610095977783, 3.3260862827301025, 3.3103246688842773, 3.294524073600769, 3.278640031814575, 3.262632727622986, 3.2464678287506104, 3.230114698410034, 3.213545083999634, 3.196734070777893, 3.1796581745147705, 3.1622960567474365, 3.1446282863616943, 3.1266363859176636, 3.1083032488822937, 3.089613139629364, 3.070551812648773, 3.0511056184768677, 3.031262755393982, 3.0110122561454773, 2.9903443455696106, 2.9692501425743103, 2.9477224349975586, 2.9257550835609436, 2.9033421874046326, 2.880480468273163, 2.857166111469269, 2.833396792411804, 2.80917090177536, 2.784486949443817, 2.759344160556793, 2.7337417602539062, 2.7076788544654846, 2.6811550855636597, 2.654168963432312, 2.6267199516296387, 2.598805844783783, 2.5704256892204285, 2.5415778756141663, 2.5122612714767456, 2.4824752807617188, 2.4522199630737305, 2.4214969873428345, 2.3903099298477173, 2.3586636781692505, 2.326566219329834, 2.2940279245376587, 2.2610623240470886, 2.2276856303215027, 2.193917214870453, 2.1597795486450195, 2.125297486782074, 2.0904985666275024, 2.0554125905036926, 2.0200711488723755, 1.9845072627067566, 1.9487548470497131, 1.912848949432373, 1.8768247961997986, 1.8407182097434998, 1.8045647144317627, 1.7683992981910706, 1.732256919145584, 1.6961716711521149, 1.6601772606372833, 1.6243070363998413, 1.5885931551456451, 1.5530677437782288, 1.517761468887329, 1.482705444097519, 1.447929561138153, 1.4134632050991058, 1.37933549284935, 1.3455745875835419, 1.312208354473114, 1.2792640030384064, 1.2467676997184753, 1.2147451043128967]\n",
            "{'DET': 0, 'NN': 1, 'V': 2, 'ADV': 3}\n",
            "['The', 'dog', 'ate', 'the', 'apple']\n",
            "['DET', 'NN', 'V', 'DET', 'NN']\n",
            "[0, 1, 2, 0, 1]\n",
            "--------------\n",
            "{'DET': 0, 'NN': 1, 'V': 2, 'ADV': 3}\n",
            "['Everybody', 'read', 'that', 'book']\n",
            "['NN', 'V', 'DET', 'NN']\n",
            "[1, 2, 0, 1]\n",
            "--------------\n",
            "{'DET': 0, 'NN': 1, 'V': 2, 'ADV': 3}\n",
            "['Everybody', 'does', 'machine', 'learning', 'nowadays']\n",
            "['NN', 'V', 'NN', 'NN', 'ADV']\n",
            "[1, 2, 1, 1, 3]\n",
            "--------------\n"
          ]
        }
      ],
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "losses = train(model, optimizer, loss_function, 100)\n",
        "print(losses)\n",
        "evaluate(model, 0)\n",
        "evaluate(model, 1)\n",
        "evaluate(model, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02SV6fDVyug0"
      },
      "source": [
        "## Replace LSTM and RNN with GRU ##\n",
        "\n",
        "Implement a network with nn.GRU, and compare with the other networks through loss and perplexity. If wanted, you can extend this toy example with more sentences or vary the task for testing the networks and observing the differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e05qXqKvyug0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BADjA_Czyug0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiBP4Xbqyug0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jts9ojcDyug0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:pDL] *",
      "language": "python",
      "name": "conda-env-pDL-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "0-getting-started-with-RNN.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}